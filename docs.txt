✅ Mẹo:
Mục	Gợi ý
Gửi Header	User-Agent, Referer, Accept-Language
Kiểm tra robots.txt	https://domain.com/robots.txt
Sử dụng delay	setTimeout / time.sleep
Kiểm tra bằng trình duyệt	Dùng Chrome DevTools (Inspect > Network)

Bạn có thể nói mình định scraping website nào cụ thể, mình sẽ giúp kiểm tra xem họ có cấm không, và hướng dẫn cách hợp pháp để làm.

Tính năng nâng cao	Mô tả
Tự động random delay	Dùng sleep(Math.random() * 3000 + 1000) để giả lập người dùng thật.
Lưu kết quả ra file	Ghi ra .json hoặc .csv thay vì chỉ console.log().
Retry khi bị lỗi	Nếu gặp lỗi mạng hoặc 403, thử lại sau 3–5 giây.
Proxy IP	Nếu scrape lớn hoặc từ nhiều vùng, có thể dùng proxy để tránh bị block IP.
Phân tích thêm dữ liệu	Ví dụ: social media, địa chỉ, Google Maps iframe, ảnh,...
Dùng thư viện chuyên kiểm tra robots.txt	Như robots-parser để phân tích chính xác hơn.

Ý tưởng nâng cao:
Thêm delay & retry để tránh bị block.

Kiểm tra robots.txt trước khi scrape.

Xử lý nhiều trang kết quả để thu thập nhiều công ty hơn.

Lưu kết quả vào file hoặc database.